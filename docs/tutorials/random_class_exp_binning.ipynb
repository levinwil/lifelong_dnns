{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages for experiment\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import keras\n",
    "\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Classification Experiment\n",
    "\n",
    "This experiment will use images from the **CIFAR 100** database (https://www.cs.toronto.edu/~kriz/cifar.html) and showcase the classification efficiency of algorithms in the **ProgLearn** project (https://github.com/neurodata/ProgLearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progressive Learning\n",
    "\n",
    "The **ProgLearn** project aims to improve program performance on sequentially learned tasks, proposing a lifelong learning approach.\n",
    "\n",
    "It contains two different algorithms: **Lifelong Learning Forests** (**L2F**) and **Lifelong Learning Network** (**L2N**). **L2F** uses Uncertainy Forest as transformers, while **L2N** uses deep networks. These two algorithms achieve both forward knowledge transfer and backward knowledge transfer, and this experiment is designed to cover the **L2F** model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing hyperparameters\n",
    "\n",
    "The hyperparameters here are used for determining how the experiment will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN HYPERPARAMS ###\n",
    "num_points_per_task = 500\n",
    "shift_num = 6\n",
    "task_num = 20\n",
    "tree_num = 10\n",
    "########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets\n",
    "\n",
    "The CIFAR 100 database contains 100 classes of 600 images, each separating into 500 training images and 100 testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image datasets from the CIFAR-100 database\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "# modify data shapes for specific model\n",
    "data_x = np.concatenate([X_train, X_test])\n",
    "data_x = data_x.reshape(\n",
    "    (data_x.shape[0], data_x.shape[1] * data_x.shape[2] * data_x.shape[3])\n",
    ")\n",
    "data_y = np.concatenate([y_train, y_test])\n",
    "data_y = data_y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.binning import KBinsDiscretize\n",
    "\n",
    "data_x5 = KBinsDiscetize(data_x, n_bins=5)\n",
    "data_x10 = KBinsDiscretize(data_x, n_bins=10)\n",
    "data_x25 = KBinsDiscretize(data_x, n_bins=20)\n",
    "data_x50 = KBinsDiscretize(data_x, n_bins=50)\n",
    "data_x100 = KBinsDiscretize(data_x, n_bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiment\n",
    "\n",
    "The following codes will run multiple experiments in parallel. For each experiment, we have task_num number of tasks. For each task, we randomly select 10 classes of the classes to train on. As we will observe below, each task increases Backwards Transfer Efficiency (BTE) with respect to Task 1 (Task 1 being the first task corresponding to 10 randomly selected classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'proglearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5301c3da302d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_class_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_parallel_exp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mslot_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_points_per_task\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mslot_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslot_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ProgLearn\\docs\\binning_experiments\\functions\\random_class_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Import the progressive learning packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mproglearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogressive_learner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProgressiveLearner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mproglearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeciders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleArgmaxAverage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mproglearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTreeClassificationTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'proglearn'"
     ]
    }
   ],
   "source": [
    "from functions.random_class_functions import run_parallel_exp\n",
    "import timeit\n",
    "\n",
    "slot_num = int(5000/num_points_per_task)\n",
    "slot_fold = range(slot_num)\n",
    "shift_fold = range(1, shift_num + 1, 1)\n",
    "times = np.empty\n",
    "# run the L2F model\n",
    "n_trees = [tree_num]\n",
    "iterable = product(n_trees, shift_fold, slot_fold)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "df_results = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(run_parallel_exp)(\n",
    "        data_x, data_y, ntree, num_points_per_task, task_num, slot=slot, shift=shift\n",
    "    )\n",
    "    for ntree, shift, slot in iterable\n",
    ")\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "times.append(elapsed)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "df_results5 = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(run_parallel_exp)(\n",
    "        data_x5, data_y, ntree, num_points_per_task, task_num, slot=slot, shift=shift\n",
    "    )\n",
    "    for ntree, shift, slot in iterable\n",
    ")\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "times.append(elapsed)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "df_results10 = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(run_parallel_exp)(\n",
    "        data_x10, data_y, ntree, num_points_per_task, task_num, slot=slot, shift=shift\n",
    "    )\n",
    "    for ntree, shift, slot in iterable\n",
    ")\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "times.append(elapsed)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "df_results25 = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(run_parallel_exp)(\n",
    "        data_x25, data_y, ntree, num_points_per_task, task_num, slot=slot, shift=shift\n",
    "    )\n",
    "    for ntree, shift, slot in iterable\n",
    ")\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "times.append(elapsed)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "df_results50 = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(run_parallel_exp)(\n",
    "        data_x50, data_y, ntree, num_points_per_task, task_num, slot=slot, shift=shift\n",
    "    )\n",
    "    for ntree, shift, slot in iterable\n",
    ")\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "times.append(elapsed)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "df_results100 = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(run_parallel_exp)(\n",
    "        data_x100, data_y, ntree, num_points_per_task, task_num, slot=slot, shift=shift\n",
    "    )\n",
    "    for ntree, shift, slot in iterable\n",
    ")\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "times.append(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting backward transfer efficiency\n",
    "\n",
    "Backward transfer efficiency (BTE) measures the relative effect of future task data on the performance on a certain task.\n",
    "\n",
    "$$BTE^t (f_n) := \\mathbb{E} [R^t (f_n^{<t} )/R^t (f_n)]$$\n",
    "\n",
    "It is the expected ratio of two risk functions of the learned hypothesis, one with access to the data up to and including the last observation from task t, and the other with access to the entire data sequence. The codes below uses the experiment results to calculate the average BTE numbers and display their changes over tasks learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.random_class_functions import calculate_results\n",
    "\n",
    "# obtain bte results\n",
    "btes = calculate_results(df_results, slot_num, shift_num)\n",
    "btes5 = calculate_results(df_results5, slot_num, shift_num)\n",
    "btes10 = calculate_results(df_results10, slot_num, shift_num)\n",
    "btes25 = calculate_results(df_results25, slot_num, shift_num)\n",
    "btes50 = calculate_results(df_results50, slot_num, shift_num)\n",
    "btes100 = calculate_results(df_results100, slot_num, shift_num)\n",
    "\n",
    "# calculate the average numbers\n",
    "bte = np.mean(btes, axis=0)\n",
    "bte5 = np.mean(btes5, axis=0)\n",
    "bte10 = np.mean(btes10, axis=0)\n",
    "bte25 = np.mean(btes25, axis=0)\n",
    "bte50 = np.mean(btes50, axis=0)\n",
    "bte100 = np.mean(btes100, axis=0)\n",
    "\n",
    "# setting plot parameters\n",
    "fontsize = 22\n",
    "ticksize = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.random_class_functions import plot_bte\n",
    "    \n",
    "plot_bte(bte, fontsize, ticksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bte(bte5, fontsize, ticksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bte(bte10, fontsize, ticksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bte(bte25, fontsize, ticksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bte(bte50, fontsize, ticksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bte(bte100, fontsize, ticksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(bins, times)\n",
    "plt.title(\"Number of Bins vs Training Time\")\n",
    "plt.xlabel(\"# of Bins\")\n",
    "plt.ylabel(\"Training Time (seconds)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
